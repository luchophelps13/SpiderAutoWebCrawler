SpiderWebCrawler is a library to automatically complete web-scraping related tasks such as:
=================================
finding element(s) by class or ID, 
finding elements by XPATH, 
finding tables, paragraphs, headers, footers, headings, images, etc., 
finding images' source, 
finding and returning images!
----------------------------------

Tutorial On Installation and Setup!!:

1. Install SpiderWebCrawler using pip âžœ "pip install SpiderWebCrawler" or "pip install SpiderWebCrawler==0.0.1" (use '!pip' if you are on Google Colab)
2. "From SWC import AutoWebScraper" AutoWebScraper is a class that you will create an instance of.
3. Use object. to view the properties/methods. Each method has a doc string so you can see what it does and its parameters.
4. Have fun!!
